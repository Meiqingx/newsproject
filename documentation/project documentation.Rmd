———
title: "Predicting Commodities Prices: A Data—Mining Approach"
author: "Rodrigo Valdés Ortiz, Meiqing Zhang, & Erin M. Ochoa"

date: "2017 March 14"
output:
  html_document:
    toc: true
———

# Description

We predict the prices of ten commodities based on a pool of 192 independent predictors:  64 first—order variables and their squared and cubic terms.

# Technical details

Python modules are designed to run in Linux on Python 3.4+; shell scripts are designed to run on GNU bash 3.2+.  Plotting requires an update to matplotlib, which requires the installation of libffi—dev, which requires an update of apt—get.

## Package installation and updates

Before running the software, please run the following commands to ensure that the necessary packages are installed and/or updated:

```{bash, eval=FALSE, highlight=TRUE, include=TRUE}
sudo pip3 install bs4
sudo pip3 install lxml
sudo pip3 install numpy
sudo pip3 install urllib
sudo pip3 install pandas
sudo pip3 install pylatex
sudo pip3 install sklearn
sudo pip3 install requests
sudo pip3 install dateutil
sudo pip3 install html2text
sudo pip3 install statsmodels

sudo apt-get update
sudo apt-get install libffi-dev
sudo apt-get build-dep matplotlib
sudo pip3 install matplotlib
sudo apt-get install texlive-latex-base
sudo apt-get install texlive-latex-extra
sudo apt-get install texlive-fonts-recommended
```

# Data crawlers and scrapers

## World Bank data
This module downloads data from the World Bank API.  
   
—filename: wbdata.py    

### Reference of supported indicators  
```
def get_countries()  
  
def get_indicators()  
  
def get_commodities()  

```

### Downloading data

```
def create_predictors_df(country_lst=None, indicator_lst=None, yymm=None, outfile='./worldbank/gem.csv')

Download 40 economic indicators from the world bank  
Parameters:  



def create_commodities_df(commodity_lst=None, indicator_lst=None, yymm=None, outfile='./worldbank/gem.csv')

Download 11 commodities by default  
Parameters:  

```

## Electricity Data

The Energy Information Administration provides a single file, which can be downloaded by hand:  http://www.eia.gov/totalenergy/data/browser/xls.cfm?tbl=T07.01

File saved to:  code/parsers/electricity_file/MER_T07_01.csv

## Precipitation Data

NASA provides 224 CSV maps of global monthly precipitation.

—filename:  code/scrapers/precipitation-emo.py

Main page:  http://neo.sci.gsfc.nasa.gov/view.php?datasetId=TRMM_3B43M&year=1998

The module scrapes the main page for each year in the data collection and determines the IDs of the files to be downloaded.  It then downloads the necessary files and outputs them with the year and month in the filename.

### Functions

```
create_output_dir():  Creates the output directory if it does not already exist.

create_main_url_list():  Creates a list of main—page URLs to be scraped.

get_csvs(queue):  Given a queue containing URLs of the files to be downloaded, downloads said files.

write_csv(csv_map,filename):  Given a single csv_map, outputs a csv file.

build_months(year):  Given a year, builds a list of the months for which data are available.

crawl_page(url,months_list,queue): Given a URL, the months for which data are available for that year, and the queue, updates the queue with the IDs of the monthly files.
```

## Recessions Data

The National Bureau of Economic Research provides a list of the start and end dates of American economic recessions.

—filename:  code/scrapers/recessions-emo.py

URL = http://www.nber.org/cycles.html

The module downloads the page, parses it, and outputs a CSV file of the start and end dates.

### Functions

```
create_output_dir():  Creates the output directory if it does not already exist.

get_page(url):  Given a URL, downloads that page and creates a BeautifulSoup object.

process_page(soup):  Processes a BeautifulSoup object and returns lists of the recession start and end dates.

clean_dates(dates):  Takes in a list of dates in 'Month YYYY' format and switches them to YYYY—MM format.

build_array(clean_start, clean_end):  Takes lists of cleaned start and end dates and makes an array of them.

write_csv(array):  Writes a CSV file from the given array.
```

## Temperature data

NASA provides global temperature difference data.

—filename:  code/scrapers/temperature/scraper_temp_rv.py

Main page:  https://data.giss.nasa.gov/gistemp

The module downloads the relevant data and outputs a single CSV file.

### Functions

```
make_output_dir():  Creates directory for output data if the directory does not already exist.

get_url_list(initial_url):  Gets the list of URLs to scrape from the main page.

save_plain_text(urls_list,base_url): Saves the extracted plaintext to .txt files.

generate_df(file):  Generates a pandas dataframe from the given filename.

gen_auxdatabases_and_names(names_files):  Given a list of filenames, generates the correct names for the databases.

compatibility(df):  Given a dataframe, produces a dataframe consistent with the output of other crawler modules that are part of the software.

join_dataframes(df_list, treated_names):  Given a list of dataframes and their correct names, joins the dataframes.

print_full(x):  Given a dataframe, prints the dataframe.
```

# Data parsing modules

## Electricity

This module parses the electricity report and outputs a properly formatted CSV file of its variables.

—filename:  code/parsers/electricity-emo.py

### Functions

```
create_output_dir():  Creates the output directory if it does not already exist.

date_fixe(date_int):  Fixes dates that come in int(YYYYMM) format and changes them to datetime objects.

build_df(filename): Given a filename, builds a pandas dataframe with one row per month and one column per variable.

write_csv(df):  Given a pandas dataframe, writes it to a CSV file.
```

## Precipitation

This module parses the precipitation CSV files and outputs a single CSV file.

—filename:  code/parsers/precipitation-emo.py

### Functions

```
gen_filenames():  Generates the filenames for the precipitation CSV maps that were downloaded via the precipitation scraper.

read_map(fname):  Creates a dataframe from the data in the file with the given filename.

calc_means(clean_map):  Calculates the global, northern, southern, and tropics precipitations means for the given map.

write_csv(array):  Given an array of monthly precipitation means, outputs a single CSV file.

process_maps(filenames):  Given a list of filenames, processes the maps found in the files and outputs a single CSV with the mean precipitation values for each month.
```

## Recessions

This module parses the recessions data and outputs a CSV file with the generated recession deltas (months elapsed since most recent recession beginning and months elapsed since most recent recession ending) for each month.

—filename:  code/parsers/recessions-emo.py

### Functions
```
read_file(fname):  Reads in the file and returns a cleaned dataframe.

date_fixer(datestring):  Takes in a date in 'YYYY Month' format and converts it to a datetime object.

build_df(clean_recessions):  Takes the cleaned dataframe and builds the output dataframe.

dy2dm(reldel):  Takes a relative delta obeject and converts it to delta—months.

def gen_months_list(clean_recessions):  Generates the list of YYYY—MMs ranging from the start of the first economic recession listed in the data to the present month.

gen_deltas(clean_recessions,months_list):  For each month in months_list, generates the months elapsed since the start of the most recent recession and the most recent recession ending.

get_dates(clean_recessions):  Returns the current date, the start date of the earliest recession, and the end date of the earliest recession, all as datetime objects.

write_csv(df):  Writes a dataframe to a CSV file.
```

# Data merging module

This module unifies data from disparate sources, outputting one CSV for predictors and another for outcomes.

—filename:  code/analysis_and_plotting/merger.py

## Functions

```
read_files():  Reads in files as pandas dataframes.  Returns a list of dataframes with preditors and a single dataframe with outcomes.

date_fixer(datestring):  Converts dates from 'YYYY—MM' to datetime format.

merge_dfs(dataframes_list):  Recursively merges dataframes in the list together (inner join based on Date).

gen_sqrs_cbcs(df):  Generates squared and cubic terms for all variables in the given dataframe.

write_csv(df,filename):  Writes a dataframe to a CSV file.
```

# Data analysis modules



# Graphing modules

We implemented two graphing modules, one for diagnostic plots and one for predictive plots.

## Diagnostic plots

This module produces a series of figures.  A single figure includes diagnostic plots for all ten outcome variables, while the diagnostic plots for the predictor variables are in a series of figures, each containing up to 50 plots.

—filename: code/analysis_and_plotting/graph_builder.py

### Functions

```
plot_a_lot(df,filename):  Plots a lot of plots in one single figure.

build_plot(dates,values,label):  Generates a single plot.

plot_plots(predictors):  Breaks predictors dataframe into chunks of many columns and generates one plot for each chunk.
```

## Predictive plots

This module produces a predictive plot from a dataframe of actual and predicted prices.

—filename: code/analysis_and_plotting/plot_pred.py

### Functions

```
build_plot(df):  Given a dataframe of dates, actual prices, and predicted prices, builds a time-series plot.
```

# Reporting module
This module creates report  
  
filename: reporting.py  

```
class Report

Parameters:

Methods:
  set_title()

  insert_graph()

  insert_table()

  generate_pdf()
```



```{r engine='python', eval=FALSE, highlight=TRUE, include=TRUE}
print('Hello, world')
```
